{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sunaguo/miniconda3/envs/torspeech/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import datetime\n",
    "import pickle as pkl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "import datasets\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, \\\n",
    "    AutoModelForQuestionAnswering, Trainer, TrainingArguments, HfArgumentParser\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ENCODER CLASS\n",
    "class BOWEncoder(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_dim, class_in, is_pretrained):\n",
    "        super(BOWEncoder, self).__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, emb_dim, padding_idx=0)\n",
    "        self.linear = nn.Linear(emb_dim,class_in)\n",
    "    \n",
    "    def forward(self, data, length):\n",
    "        \"\"\"\n",
    "        \n",
    "        @param data: matrix of size (batch_size, max_sentence_length). Each row in data represents a \n",
    "            review that is represented using n-gram index. Note that they are padded to have same length.\n",
    "        @param length: an int tensor of size (batch_size), which represents the non-trivial (excludes padding)\n",
    "            length of each sentences in the data.\n",
    "        \"\"\"\n",
    "        out = self.embed(data)\n",
    "        out = torch.sum(out, dim=1)\n",
    "        out /= length.view(length.size()[0],1).expand_as(out).float()\n",
    "     \n",
    "        out = self.linear(out.float())\n",
    "        return out\n",
    "    \n",
    "    def create_weights(self, vectors, id2token):\n",
    "        '''Create weights metrics from vectors and id2token\n",
    "        Returns:\n",
    "        weights_matrix: torch.Tensor, dimension of (vocab size x embedding dim)\n",
    "        '''\n",
    "        weights_matrix = torch.from_numpy(np.array([vectors[id2token[i]] for i in range(2, len(id2token))]))\n",
    "        zero = torch.zeros(2, weights_matrix.size()[1], dtype=torch.float64)\n",
    "        weights_matrix = torch.cat([zero, weights_matrix])\n",
    "        return weights_matrix\n",
    "\n",
    "    \n",
    "    def create_emb_layer(self, weights_matrix, non_trainable=False):\n",
    "        '''Create embedding layer that's used in a PyTorch model\n",
    "        Returns:\n",
    "        emb_layer: nn.Embedding()\n",
    "        num_embeddings: int\n",
    "        embedding_dim: int\n",
    "        '''\n",
    "        num_embeddings, embedding_dim = weights_matrix.size()\n",
    "        emb_layer = nn.Embedding(num_embeddings, embedding_dim)\n",
    "        emb_layer.load_state_dict({'weight': weights_matrix})\n",
    "        if non_trainable:\n",
    "            emb_layer.weight.requires_grad = False\n",
    "        return emb_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class NNClassifier(nn.Module):\n",
    "    def __init__(self, n_in, h_s, n_out):\n",
    "        super().__init__()\n",
    "#         self.linear1 = nn.Linear(n_in,h_s)\n",
    "#         self.linear2 = nn.Linear(h_s,h_s)\n",
    "#         self.linear3 = nn.Linear(h_s,n_out)\n",
    "    \n",
    "    def forward(self, x):\n",
    "#         x = F.relu(self.linear1(x))\n",
    "#         x = self.linear2(x)\n",
    "#         x = F.relu(x)\n",
    "#         x = self.linear3(x)\n",
    "        return F.log_softmax(x)\n",
    "    \n",
    "\n",
    "class NNModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, n_in, h_s, n_out, combine_mode, is_pretrained):\n",
    "        super().__init__()\n",
    "        self.encoder = BOWEncoder(vocab_size, embed_dim, n_in, is_pretrained)\n",
    "        self.combine_mode = combine_mode\n",
    "        if combine_mode == 'DIRECT':\n",
    "            n_in = n_in * 2;\n",
    "        self.classifier = NNClassifier(n_in,h_s, n_out)\n",
    "    \n",
    "    def forward(self, premise, len_premise, ):  #hypothesis, len_hypo\n",
    "        premise = self.encoder(premise, )  #len_premise\n",
    "        x = premise\n",
    "#         hypothesis = self.encoder(hypothesis, len_hypo)\n",
    "#         if self.combine_mode == 'DIRECT':\n",
    "#             x = torch.cat((premise, hypothesis),1)\n",
    "#         elif self.combine_mode == 'MUL':\n",
    "#             x = torch.mul(premise, hypothesis)\n",
    "#         elif self.combine_mode == 'SUB':\n",
    "#             x = torch.sub(premise, hypothesis)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ENCODER CLASS\n",
    "class BOWEncoder(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_dim, class_in):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, emb_dim, padding_idx=0)\n",
    "        self.linear = nn.Linear(emb_dim,class_in)\n",
    "        self.logits = None\n",
    "        self.sm = nn.LogSoftmax(dim=-1)\n",
    "    \n",
    "    def forward(self, data, length):\n",
    "        \"\"\"\n",
    "        @param data: matrix of size (batch_size, max_sentence_length). Each row in data represents a \n",
    "            review that is represented using n-gram index. Note that they are padded to have same length.\n",
    "        @param length: an int tensor of size (batch_size), which represents the non-trivial (excludes padding)\n",
    "            length of each sentences in the data.\n",
    "        \"\"\"\n",
    "        out = self.embed(data)  ## batch x maxlen x emb\n",
    "        print(\"emb\", out.shape)\n",
    "        out = out.sum(dim=1)  ## batch x emb\n",
    "        print(\"sum\", out.shape)\n",
    "        out /= length.view(length.size()[0],1).expand_as(out).float()\n",
    "        print(\"avg\", out.shape)\n",
    "     \n",
    "        out = self.linear(out.float())\n",
    "        print(\"out\", out.shape)\n",
    "        self.logits = out.detach()\n",
    "    \n",
    "        out = self.sm(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = BOWEncoder(tokenizer.vocab_size, 128, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 100]), torch.Size([2]))"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor(np.random.rand(2,100)).int()\n",
    "l = torch.tensor([1,2]).int()\n",
    "\n",
    "x.shape, l.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 100, 128])\n",
      "torch.Size([2, 128])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 128])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o = m.embed(x)\n",
    "print(o.shape)\n",
    "o = o.sum(dim=1)\n",
    "print(o.shape)\n",
    "o /= l.view(l.size()[0],1).expand_as(o).float()\n",
    "o.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = m(x, l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3208, 0.3112, 0.3680]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3208, 0.3112, 0.3680]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import prepare_dataset_nli\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('google/electra-small-discriminator', use_fast=True)\n",
    "\n",
    "prepare_train_dataset = prepare_eval_dataset = \\\n",
    "    lambda exs: prepare_dataset_nli(exs, tokenizer, 128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/home/sunaguo/.cache/huggingface/datasets/parquet/plain_text-ac8034d49bf805ac/0.0.0/14a00e99c0d15a23649d0db8944380ac81082d4b021f398733dd84f3a6c569a7)\n",
      "100%|██████████| 3/3 [00:00<00:00, 107.67it/s]\n",
      "Loading cached processed dataset at /home/sunaguo/.cache/huggingface/datasets/parquet/plain_text-ac8034d49bf805ac/0.0.0/14a00e99c0d15a23649d0db8944380ac81082d4b021f398733dd84f3a6c569a7/cache-9a809bd4db7edce2.arrow\n",
      "Loading cached processed dataset at /home/sunaguo/.cache/huggingface/datasets/parquet/plain_text-ac8034d49bf805ac/0.0.0/14a00e99c0d15a23649d0db8944380ac81082d4b021f398733dd84f3a6c569a7/cache-70ef6e5e2f5d1d70.arrow\n",
      "Loading cached processed dataset at /home/sunaguo/.cache/huggingface/datasets/parquet/plain_text-ac8034d49bf805ac/0.0.0/14a00e99c0d15a23649d0db8944380ac81082d4b021f398733dd84f3a6c569a7/cache-0262eb9dc529825e.arrow\n",
      "Loading cached processed dataset at /home/sunaguo/.cache/huggingface/datasets/parquet/plain_text-ac8034d49bf805ac/0.0.0/14a00e99c0d15a23649d0db8944380ac81082d4b021f398733dd84f3a6c569a7/cache-64f6ed18a9b1be7f_*_of_00002.arrow\n",
      "Loading cached processed dataset at /home/sunaguo/.cache/huggingface/datasets/parquet/plain_text-ac8034d49bf805ac/0.0.0/14a00e99c0d15a23649d0db8944380ac81082d4b021f398733dd84f3a6c569a7/cache-7163b6c7f98e416a_*_of_00002.arrow\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dataset = datasets.load_dataset('snli')\n",
    "dataset = dataset.filter(lambda ex: ex['label'] != -1)\n",
    "\n",
    "\n",
    "train_dataset = dataset['train']\n",
    "train_dataset_featurized = train_dataset.map(\n",
    "    prepare_train_dataset,\n",
    "    batched=True,\n",
    "    num_proc=2,\n",
    "    remove_columns=train_dataset.column_names\n",
    ")\n",
    "\n",
    "eval_dataset = dataset['validation']\n",
    "eval_dataset_featurized = eval_dataset.map(\n",
    "    prepare_eval_dataset,\n",
    "    batched=True,\n",
    "    num_proc=2,\n",
    "    remove_columns=eval_dataset.column_names\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(549367, 9842)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset_featurized), len(eval_dataset_featurized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(550152, 10000)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset_featurized), len(eval_dataset_featurized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-small-discriminator were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense.bias', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense_prediction.weight']\n",
      "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at google/electra-small-discriminator and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "## getting pretrained embedding\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "modelname = 'google/electra-small-discriminator'\n",
    "task_kwargs = {'num_labels': 3} \n",
    "basemodel = AutoModelForSequenceClassification.from_pretrained(modelname, **task_kwargs)\n",
    "emb = basemodel.electra.embeddings.word_embeddings.weight.detach()\n",
    "\n",
    "EMBEDDING_DIM =  emb.shape[1]\n",
    "\n",
    "emb[tokenizer.all_special_ids] = torch.zeros(EMBEDDING_DIM)\n",
    "\n",
    "basemodel.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30522"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = emb.shape[0]\n",
    "emb_dim = 128\n",
    "nclass = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "## vocab_size, emb_dim, class_in\n",
    "model = BOWEncoder(vocab_size, emb_dim, nclass)\n",
    "for p in model.parameters():\n",
    "    if p.dim() > 1:\n",
    "        nn.init.xavier_uniform_(p)   \n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "criterion = nn.NLLLoss()\n",
    "lsm = nn.LogSoftmax(dim=1)\n",
    "\n",
    "save_path = 'bow.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0079, -0.0102, -0.0112,  ..., -0.0088, -0.0026, -0.0034],\n",
       "        [ 0.0023, -0.0035, -0.0013,  ..., -0.0008,  0.0026, -0.0093],\n",
       "        [ 0.0094, -0.0061, -0.0060,  ...,  0.0082,  0.0028, -0.0112],\n",
       "        ...,\n",
       "        [ 0.0012, -0.0039, -0.0129,  ...,  0.0040, -0.0040,  0.0005],\n",
       "        [ 0.0027,  0.0030,  0.0068,  ..., -0.0020,  0.0061,  0.0076],\n",
       "        [ 0.0110,  0.0119, -0.0117,  ..., -0.0039,  0.0134,  0.0121]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embed.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0780,  0.0105, -0.1745, -0.2116,  0.2044,  0.0911,  0.0927,  0.1407,\n",
       "          0.2012, -0.2002, -0.1130,  0.1948, -0.1500, -0.1252, -0.0950,  0.0979,\n",
       "         -0.0300, -0.0279, -0.0903,  0.1281,  0.0245, -0.2033,  0.1830,  0.0037,\n",
       "          0.1137,  0.1143,  0.1439, -0.1793, -0.0927,  0.1774,  0.0944, -0.1786,\n",
       "          0.0226, -0.1434,  0.1764,  0.0614, -0.1071, -0.0979, -0.0329, -0.1652,\n",
       "         -0.0544,  0.0581, -0.0399, -0.0442, -0.0979, -0.1933, -0.1237,  0.1137,\n",
       "          0.0281, -0.0073, -0.1676,  0.0246, -0.1775, -0.0671,  0.1329,  0.0459,\n",
       "         -0.1396, -0.0957, -0.1236, -0.0892,  0.0220,  0.1763,  0.2124,  0.0200,\n",
       "         -0.1425, -0.1426, -0.1543, -0.1153, -0.0663, -0.0267, -0.0763, -0.0009,\n",
       "          0.0726, -0.0704, -0.1711,  0.0104,  0.1853, -0.1232, -0.1810, -0.0519,\n",
       "          0.2046,  0.0765,  0.0894,  0.0077, -0.1509, -0.0995, -0.0006, -0.0833,\n",
       "          0.0570, -0.1613,  0.1782, -0.0965,  0.0696, -0.1400,  0.2038, -0.0241,\n",
       "         -0.2096, -0.1889, -0.0490,  0.1551, -0.0318, -0.2061,  0.1734, -0.1604,\n",
       "          0.0432, -0.0256,  0.1740, -0.1004, -0.0454,  0.1689,  0.0149,  0.1945,\n",
       "          0.1383,  0.0206, -0.1082,  0.1270,  0.0081,  0.1097, -0.1633, -0.1702,\n",
       "         -0.0545, -0.1340, -0.1223,  0.1681,  0.0468, -0.0414, -0.1324, -0.1172],\n",
       "        [ 0.1146, -0.2074, -0.1363, -0.0502, -0.0032, -0.1099,  0.0659,  0.1335,\n",
       "          0.0294, -0.0298,  0.1529, -0.0214,  0.0086,  0.0028, -0.1953, -0.0494,\n",
       "          0.1498,  0.2053,  0.1871,  0.1541,  0.0169,  0.1859, -0.0684,  0.1446,\n",
       "          0.0862,  0.0376, -0.2111,  0.0607,  0.0299,  0.1184,  0.1702, -0.0012,\n",
       "          0.1036, -0.1545,  0.2095, -0.0880, -0.1620, -0.1169,  0.0299,  0.1287,\n",
       "         -0.0968, -0.0742, -0.1418, -0.1767, -0.0563, -0.0278, -0.0066,  0.1888,\n",
       "          0.2080,  0.0528, -0.0251,  0.1434,  0.1413, -0.0479, -0.0320, -0.1411,\n",
       "         -0.1503,  0.0433,  0.2134,  0.1529,  0.1993,  0.0345, -0.0654,  0.0298,\n",
       "          0.0797,  0.1670, -0.0859, -0.0203,  0.0350,  0.1890,  0.1904, -0.1491,\n",
       "          0.1003, -0.1425,  0.1736,  0.0179,  0.0265, -0.0256,  0.1240,  0.2019,\n",
       "         -0.0192,  0.0192,  0.0342,  0.2068,  0.0197,  0.1680,  0.1916,  0.0217,\n",
       "          0.1935,  0.1576,  0.0394, -0.1665,  0.2004,  0.0248,  0.0295, -0.0342,\n",
       "         -0.0171,  0.1829, -0.0071, -0.1413, -0.1654,  0.1915, -0.0604,  0.0212,\n",
       "         -0.1785, -0.0759, -0.1966,  0.2043, -0.1326, -0.0547, -0.1275,  0.0053,\n",
       "          0.2017,  0.0233,  0.0526,  0.0841,  0.1775, -0.1400, -0.1803,  0.1613,\n",
       "         -0.1389, -0.0180, -0.1133, -0.1505,  0.0863,  0.1345, -0.1514,  0.0588],\n",
       "        [ 0.1414, -0.1686,  0.1258,  0.1775,  0.1590,  0.1484,  0.1530,  0.1644,\n",
       "         -0.1298,  0.0246, -0.0097, -0.1043, -0.1102,  0.1063,  0.2134,  0.0444,\n",
       "         -0.0641,  0.1029, -0.1342,  0.1476, -0.0483,  0.1936, -0.0571, -0.1900,\n",
       "          0.2094, -0.0482,  0.0898, -0.1522, -0.1149,  0.1044,  0.1161,  0.1289,\n",
       "          0.1000, -0.0721, -0.1919, -0.0635, -0.1648,  0.2084, -0.0153, -0.0089,\n",
       "          0.0493,  0.1491, -0.1421,  0.1866, -0.1773, -0.0417, -0.1370,  0.1651,\n",
       "         -0.1252, -0.0464,  0.0684, -0.0359,  0.0900, -0.1908,  0.0616, -0.2125,\n",
       "          0.0925,  0.0993,  0.0006, -0.1687,  0.1816,  0.0559, -0.1450, -0.1502,\n",
       "         -0.0529,  0.0171, -0.0598, -0.1105,  0.1703,  0.1325,  0.1335,  0.1995,\n",
       "          0.1264, -0.0628,  0.0384,  0.0439,  0.1820, -0.1883, -0.1128, -0.1028,\n",
       "         -0.1580,  0.1442, -0.0811, -0.0574, -0.0691, -0.1063,  0.0672, -0.1914,\n",
       "         -0.0315,  0.1528,  0.1371, -0.0618,  0.0757,  0.0183, -0.0833,  0.0033,\n",
       "          0.0553,  0.1258,  0.1667, -0.1125,  0.1200,  0.1307, -0.1912,  0.0472,\n",
       "         -0.0951, -0.0234, -0.0950,  0.0867,  0.0514, -0.0957, -0.1451, -0.1027,\n",
       "          0.1687,  0.0434, -0.0084, -0.0607, -0.1807,  0.1690,  0.0977,  0.0201,\n",
       "          0.0497,  0.0196, -0.0689, -0.0932,  0.1789,  0.1359, -0.0188,  0.0651]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.linear.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.embed.weight.data.copy_(emb)\n",
    "\n",
    "model.embed.weight.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0271,  0.0583, -0.0169,  ..., -0.0071,  0.0726,  0.0497],\n",
       "        [ 0.0272,  0.0583, -0.0171,  ..., -0.0070,  0.0728,  0.0496],\n",
       "        ...,\n",
       "        [ 0.0267,  0.0577, -0.0167,  ..., -0.0071,  0.0724,  0.0492],\n",
       "        [ 0.0275,  0.0583, -0.0170,  ..., -0.0070,  0.0731,  0.0496],\n",
       "        [ 0.0263,  0.0573, -0.0160,  ..., -0.0063,  0.0715,  0.0492]])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embed.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 128])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/17168 [00:03<2:35:21,  1.84it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 1 | Train Loss: 1.0991970300674438 | Val Loss: 338.31070363521576 | Val Accuracy: 0.348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 1008/17168 [00:31<46:35,  5.78it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 1001 | Train Loss: 1.0844221115112305 | Val Loss: 334.4391733407974 | Val Accuracy: 0.438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 2005/17168 [00:59<59:44,  4.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 2001 | Train Loss: 1.068668246269226 | Val Loss: 329.36107552051544 | Val Accuracy: 0.461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 3009/17168 [01:26<40:34,  5.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 3001 | Train Loss: 1.0415328741073608 | Val Loss: 324.40881329774857 | Val Accuracy: 0.472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 4009/17168 [01:54<37:42,  5.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 4001 | Train Loss: 1.0505361557006836 | Val Loss: 320.2888207435608 | Val Accuracy: 0.483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 5009/17168 [02:22<34:53,  5.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 5001 | Train Loss: 1.0537341833114624 | Val Loss: 316.96708446741104 | Val Accuracy: 0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 6009/17168 [02:49<31:58,  5.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 6001 | Train Loss: 0.9865809679031372 | Val Loss: 314.1910751461983 | Val Accuracy: 0.504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 7009/17168 [03:17<29:17,  5.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 7001 | Train Loss: 1.1000862121582031 | Val Loss: 312.05656093358994 | Val Accuracy: 0.512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 8007/17168 [03:45<26:26,  5.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 8001 | Train Loss: 1.001775860786438 | Val Loss: 310.1687545776367 | Val Accuracy: 0.518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 9006/17168 [04:13<23:25,  5.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 9001 | Train Loss: 0.9694463610649109 | Val Loss: 308.5297416448593 | Val Accuracy: 0.522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 10008/17168 [04:41<20:40,  5.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 10001 | Train Loss: 0.9584894180297852 | Val Loss: 307.05324923992157 | Val Accuracy: 0.524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 11005/17168 [05:09<24:14,  4.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 11001 | Train Loss: 1.0768154859542847 | Val Loss: 305.9373205304146 | Val Accuracy: 0.527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 12005/17168 [05:38<20:20,  4.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 12001 | Train Loss: 0.9610840678215027 | Val Loss: 304.8757339119911 | Val Accuracy: 0.533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 13005/17168 [06:06<12:38,  5.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 13001 | Train Loss: 0.9883594512939453 | Val Loss: 303.7991444468498 | Val Accuracy: 0.533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 14007/17168 [06:34<09:36,  5.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 14001 | Train Loss: 1.1926300525665283 | Val Loss: 302.9394243955612 | Val Accuracy: 0.534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 15008/17168 [07:02<06:14,  5.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 15001 | Train Loss: 0.9064332842826843 | Val Loss: 302.23910760879517 | Val Accuracy: 0.534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 16008/17168 [07:30<03:30,  5.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 16001 | Train Loss: 0.8755434155464172 | Val Loss: 301.5549948811531 | Val Accuracy: 0.538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 17005/17168 [07:58<00:38,  4.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 17001 | Train Loss: 0.9976648092269897 | Val Loss: 300.94450026750565 | Val Accuracy: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17168/17168 [08:02<00:00, 35.56it/s]\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 1\n",
    "best_accuracy = 0\n",
    "batch_size = 32\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for bii in tqdm(range(len(train_dataset_featurized)//batch_size+1)):\n",
    "        batchd = train_dataset_featurized[bii*batch_size:(bii+1)*batch_size]\n",
    "        \n",
    "        xs = torch.tensor(batchd[\"input_ids\"])\n",
    "#         print(\"xs\", xs.shape)\n",
    "        lens = (xs != 0).sum(1)\n",
    "#         print(\"lens\", lens.shape)\n",
    "        labels = torch.tensor(batchd['label'])\n",
    "#         print(\"labels\", labels.shape)\n",
    "        \n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        logprobs = model(xs, lens) \n",
    "#         print(\"logits\", labels.shape)\n",
    "#         logprobs = lsm(logits)\n",
    "#         print(\"logprobs\", labels.shape)\n",
    "        loss = criterion(logprobs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if bii % 1000 == 0:  \n",
    "            train_loss = loss.item()\n",
    "            \n",
    "            model.eval()\n",
    "            correct = 0\n",
    "            val_loss = 0.\n",
    "\n",
    "            for evbii in range(len(eval_dataset_featurized)//batch_size+1):\n",
    "                batchd = eval_dataset_featurized[evbii*batch_size:(evbii+1)*batch_size]\n",
    "\n",
    "                xs = torch.tensor(batchd[\"input_ids\"])\n",
    "    #             print(\"xs\", xs.shape)\n",
    "                lens = (xs != 0).sum(1)\n",
    "    #             print(\"lens\", lens.shape)\n",
    "                labels = torch.tensor(batchd['label'])\n",
    "    #             print(\"labels\", labels.shape)\n",
    "\n",
    "                logprobs = model(xs, lens) \n",
    "    #             print(\"logits\", logits.shape)\n",
    "#                 logprobs = lsm(logits)\n",
    "    #             print(\"logprobs\", logprobs.shape)\n",
    "\n",
    "                loss = criterion(logprobs, labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                preds = torch.argmax(logprobs, dim=-1)\n",
    "    #             print(\"preds\", preds.shape)\n",
    "                correct += (preds == labels).sum().numpy()\n",
    "\n",
    "            accuracy = correct / len(eval_dataset_featurized)\n",
    "            if accuracy > best_accuracy:\n",
    "                best_accuracy = accuracy\n",
    "                torch.save(model.state_dict(), save_path)\n",
    "\n",
    "            print('Batch: {} | Train Loss: {} | Val Loss: {} | Val Accuracy: {}'.format(\n",
    "                (bii+1), train_loss, val_loss, round(accuracy, 3)\n",
    "            ))\n",
    "\n",
    "#     print('Epoch: {} | Train Loss: {} | Val Loss: {} | Val Accuracy: {}'.format(\n",
    "#         (epoch+1), train_loss, val_loss, round(accuracy, 3)\n",
    "#     ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = [1.09919703, 1.084422112, 1.068668246, 1.041532874, 1.050536156, 1.053734183, 0.9865809679, 1.100086212, 1.001775861, 0.9694463611, 0.958489418, 1.076815486, 0.9610840678, 0.9883594513, 1.192630053, 0.9064332843, 0.8755434155]\n",
    "val_losses = [338.3107036, 334.4391733, 329.3610755, 324.4088133, 320.2888207, 316.9670845, 314.1910751, 312.0565609, 310.1687546, 308.5297416, 307.0532492, 305.9373205, 304.8757339, 303.7991444, 302.9394244, 302.2391076, 301.5549949]\n",
    "val_accs = [0.348, 0.438, 0.461, 0.472, 0.483, 0.497, 0.504, 0.512, 0.518, 0.522, 0.524, 0.527, 0.533, 0.533, 0.534, 0.534, 0.538]\n",
    "\n",
    "np.savez(\"data/fasttext_train_stats\", train_losses=train_losses, val_losses=val_losses, val_accs=val_accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "torch.save(model.state_dict(), \"bow_best.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3382442592968909, 0.3286933550091445, 0.3330623856939646]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = np.array(eval_dataset_featurized[\"label\"])\n",
    "perc = [(d == ii).sum()/len(d) for ii in range(3)]\n",
    "perc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0271,  0.0583, -0.0169,  ..., -0.0071,  0.0726,  0.0497],\n",
       "        [ 0.0272,  0.0583, -0.0171,  ..., -0.0070,  0.0728,  0.0496],\n",
       "        ...,\n",
       "        [ 0.0267,  0.0577, -0.0167,  ..., -0.0071,  0.0724,  0.0492],\n",
       "        [ 0.0275,  0.0583, -0.0170,  ..., -0.0070,  0.0731,  0.0496],\n",
       "        [ 0.0263,  0.0573, -0.0160,  ..., -0.0063,  0.0715,  0.0492]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embed.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get electra logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BOWEncoder(\n",
       "  (embed): Embedding(30522, 128, padding_idx=0)\n",
       "  (linear): Linear(in_features=128, out_features=3, bias=True)\n",
       "  (sm): LogSoftmax(dim=-1)\n",
       ")"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.load(\"bow_best.pt\")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ElectraForSequenceClassification(\n",
       "  (electra): ElectraModel(\n",
       "    (embeddings): ElectraEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 128, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 128)\n",
       "      (token_type_embeddings): Embedding(2, 128)\n",
       "      (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (embeddings_project): Linear(in_features=128, out_features=256, bias=True)\n",
       "    (encoder): ElectraEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): ElectraClassificationHead(\n",
       "    (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=256, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "basemodel.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([23, 128]), torch.Size([23]), torch.Tensor, torch.Tensor)"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs.shape, lens.shape, type(xs), type(lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 128]), torch.Size([1]), torch.Tensor, torch.Tensor)"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor(np.random.randint(0,30000, (1,128)))\n",
    "l = torch.tensor([20]).int()\n",
    "x.shape, l.shape, type(x), type(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BOWEncoder(\n",
       "  (embed): Embedding(30522, 128, padding_idx=0)\n",
       "  (linear): Linear(in_features=128, out_features=3, bias=True)\n",
       "  (sm): LogSoftmax(dim=-1)\n",
       ")"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = BOWEncoder(30522, 128, 3)\n",
    "m.load_state_dict(torch.load(\"bow_best.pt\"))\n",
    "m.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([20], dtype=torch.int32)"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[20]], dtype=torch.int32)"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l.view(l.size()[0],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length.view(length.size()[0],1).expand_as(out).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emb torch.Size([1, 128, 128])\n",
      "sum torch.Size([1, 128])\n",
      "avg torch.Size([1, 128])\n",
      "out torch.Size([1, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-2.7361, -0.3920, -1.3492]], grad_fn=<LogSoftmaxBackward0>)"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m(x,l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([23, 3])"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_ = model(xs, lens)\n",
    "fl = model.logits\n",
    "fl.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([23, 3])"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bl = basemodel(xs).logits\n",
    "bl.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss2 = nn.NLLLoss(reduce=False, reduction=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.7051, 0.3321, 1.0375, 1.2840, 1.3471, 0.8026, 0.8340, 0.6849, 1.1850,\n",
       "        1.5402, 0.5908, 0.7205, 0.9859, 0.9000, 1.3907, 0.1224, 1.4801, 0.4347,\n",
       "        1.8268, 0.4064, 0.7410, 1.1999, 0.6720], grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "logprobs = model(xs, lens)\n",
    "loss2(logprobs, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 1.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.],\n",
       "        [1., 0., 0.]])"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_onehot = torch.zeros(23, 3)\n",
    "# scatter will write the value of 1 into the position of y_onehot given by y\n",
    "y_onehot.scatter_(1, labels.unsqueeze(1), 1)\n",
    "\n",
    "# y_onehot = torch.tensor([0,1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0477,  0.0331, -0.1686],\n",
       "        [ 0.0454,  0.0332, -0.1667],\n",
       "        [ 0.0319,  0.0352, -0.1552],\n",
       "        [ 0.0310,  0.0385, -0.1478],\n",
       "        [ 0.0309,  0.0374, -0.1514],\n",
       "        [ 0.0362,  0.0275, -0.1516],\n",
       "        [ 0.0364,  0.0275, -0.1554],\n",
       "        [ 0.0350,  0.0363, -0.1464],\n",
       "        [ 0.0339,  0.0423, -0.1424],\n",
       "        [ 0.0338,  0.0428, -0.1424],\n",
       "        [ 0.0392,  0.0442, -0.1516],\n",
       "        [ 0.0288,  0.0444, -0.1412],\n",
       "        [ 0.0308,  0.0429, -0.1403],\n",
       "        [ 0.0309,  0.0467, -0.1418],\n",
       "        [ 0.0291,  0.0372, -0.1387],\n",
       "        [ 0.0307,  0.0376, -0.1426],\n",
       "        [ 0.0306,  0.0367, -0.1454],\n",
       "        [ 0.0300,  0.0350, -0.1465],\n",
       "        [ 0.0397,  0.0401, -0.1579],\n",
       "        [ 0.0351,  0.0330, -0.1586],\n",
       "        [ 0.0381,  0.0307, -0.1674],\n",
       "        [ 0.0423,  0.0359, -0.1709],\n",
       "        [ 0.0375,  0.0262, -0.1623]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.2427, -1.0407, -1.0412, -1.0376, -1.2261, -1.2246, -1.0444, -1.0422,\n",
       "        -1.0378, -1.2227, -1.0407, -1.0506, -1.2202, -1.0341, -1.2164, -1.0465,\n",
       "        -1.0394, -1.0450, -1.2347, -1.0395, -1.0395, -1.2434, -1.0324],\n",
       "       grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = lsm(bl).mul(y_onehot).sum(-1)\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.0726, -1.0612, -1.0753, -1.0754, -1.0855, -1.1199, -1.1059, -1.0947,\n",
       "        -1.0790, -1.0793, -1.0770, -1.0778, -1.1069, -1.0835, -1.0863, -1.0516,\n",
       "        -1.0658, -1.0653, -1.0661, -1.0631, -1.0797, -1.0929, -1.0824],\n",
       "       grad_fn=<LogBackward0>)"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "r = torch.log(torch.softmax(fl,-1).mul(torch.softmax(bl,-1)).sum(-1))\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.7114, -0.6468, -0.6470, -0.6457, -0.7066, -0.7061, -0.6481, -0.6473,\n",
       "        -0.6458, -0.7056, -0.6468, -0.6503, -0.7048, -0.6444, -0.7037, -0.6488,\n",
       "        -0.6463, -0.6483, -0.7091, -0.6464, -0.6464, -0.7116, -0.6438],\n",
       "       grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(l.sub(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(484.8472, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(l.sub(r)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.2886, -0.3532, -0.3530, -0.3543, -0.2934, -0.2939, -0.3519, -0.3527,\n",
       "        -0.3542, -0.2944, -0.3532, -0.3497, -0.2952, -0.3556, -0.2963, -0.3512,\n",
       "        -0.3537, -0.3517, -0.2909, -0.3536, -0.3536, -0.2884, -0.3562],\n",
       "       grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "logprobs = lsm(basemodel(xs).logits)\n",
    "loss2(logprobs, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## eval base electra wrong sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BOWEncoder(\n",
       "  (embed): Embedding(30522, 128, padding_idx=0)\n",
       "  (linear): Linear(in_features=128, out_features=3, bias=True)\n",
       "  (sm): LogSoftmax(dim=-1)\n",
       ")"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9842,)"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allpreds = []\n",
    "for evbii in range(len(eval_dataset_featurized)//batch_size+1):\n",
    "    batchd = eval_dataset_featurized[evbii*batch_size:(evbii+1)*batch_size]\n",
    "\n",
    "    xs = torch.tensor(batchd[\"input_ids\"])\n",
    "#             print(\"xs\", xs.shape)\n",
    "    lens = (xs != 0).sum(1)\n",
    "#             print(\"lens\", lens.shape)\n",
    "#     labels = torch.tensor(batchd['label'])\n",
    "#             print(\"labels\", labels.shape)\n",
    "\n",
    "    logprobs = model(xs, lens) \n",
    "#             print(\"logits\", logits.shape)\n",
    "#                 logprobs = lsm(logits)\n",
    "#             print(\"logprobs\", logprobs.shape)\n",
    "\n",
    "    preds = torch.argmax(logprobs, dim=-1)\n",
    "    \n",
    "    allpreds += preds.tolist()\n",
    "    \n",
    "allpreds = np.array(allpreds)\n",
    "allpreds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = eval_dataset_featurized[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"data/fasttext_eval_preds\", allpreds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torspeech] *",
   "language": "python",
   "name": "conda-env-torspeech-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "336px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "495.852px",
    "left": "1343px",
    "right": "20px",
    "top": "120px",
    "width": "317px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
